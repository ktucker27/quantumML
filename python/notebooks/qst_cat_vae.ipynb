{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 6), \"Sonnet 2 requires Python >=3.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 2.3.1\n",
      "Sonnet version 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tree\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "  import sonnet.v2 as snt\n",
    "  tf.enable_v2_behavior()\n",
    "except ImportError:\n",
    "  import sonnet as snt\n",
    "\n",
    "print(\"TensorFlow version {}\".format(tf.__version__))\n",
    "print(\"Sonnet version {}\".format(snt.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'vae' from '../models/vae.py'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_data = pd.read_table('/Users/tuckerkj/Google Drive/Research/QML/data/quc_examples/Tutorial1_TrainPosRealWaveFunction/tfim1d_data.txt', delimiter=' ', usecols=range(10)).values\n",
    "is_train = is_data[0:7999]\n",
    "is_test = is_data[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = is_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "learning_rate = 3e-4\n",
    "input_shape = (original_dim, )\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "depth = 2\n",
    "\n",
    "# F = 0.8960\n",
    "intermediate_dim = [100]\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "learning_rate = 3e-4\n",
    "input_shape = (original_dim, )\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "depth = 2\n",
    "\n",
    "# F = 0.9322\n",
    "#intermediate_dim = [500, 500]\n",
    "#latent_dim = 10\n",
    "\n",
    "# F = 0.9255\n",
    "#intermediate_dim = [100]\n",
    "#latent_dim = 4\n",
    "\n",
    "# F = 0.8989\n",
    "intermediate_dim = [100]\n",
    "latent_dim = 2\n",
    "\n",
    "optimizer = snt.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "enc = vae.CatEncoder(intermediate_dim, latent_dim, depth)\n",
    "dec = vae.CatDecoder(intermediate_dim, original_dim, depth)\n",
    "catvae = vae.CatVAE(enc, dec)\n",
    "\n",
    "@tf.function\n",
    "def train_step(data):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model_output = catvae(tf.cast(data, tf.int32))\n",
    "    \n",
    "    trainable_variables = catvae.trainable_variables\n",
    "    grads = tape.gradient(model_output['loss'], trainable_variables)\n",
    "    optimizer.apply(grads, trainable_variables)\n",
    "    \n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data sliced for SGD\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(is_train)\n",
    "    .shuffle(1000)\n",
    "    .repeat(-1)  # repeat indefinitely\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .prefetch(-1))\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(is_test)\n",
    "    .repeat(1)  # 1 epoch\n",
    "    .batch(batch_size)\n",
    "    .prefetch(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loss: 7.106334 recon loss: 6.937060\n",
      "200 loss: 6.213257 recon loss: 5.606678\n",
      "300 loss: 5.912413 recon loss: 5.103334\n",
      "400 loss: 5.801593 recon loss: 4.939638\n",
      "500 loss: 5.695118 recon loss: 4.728037\n",
      "600 loss: 5.595801 recon loss: 4.456376\n",
      "700 loss: 5.556584 recon loss: 4.302936\n",
      "800 loss: 5.534577 recon loss: 4.263422\n",
      "900 loss: 5.522062 recon loss: 4.239207\n",
      "1000 loss: 5.534912 recon loss: 4.244057\n",
      "1100 loss: 5.523646 recon loss: 4.226972\n",
      "1200 loss: 5.510580 recon loss: 4.208869\n",
      "1300 loss: 5.514606 recon loss: 4.206976\n",
      "1400 loss: 5.501201 recon loss: 4.196276\n",
      "1500 loss: 5.499741 recon loss: 4.185254\n",
      "1600 loss: 5.513560 recon loss: 4.195140\n",
      "1700 loss: 5.496112 recon loss: 4.176683\n",
      "1800 loss: 5.500017 recon loss: 4.181344\n",
      "1900 loss: 5.506378 recon loss: 4.184157\n",
      "2000 loss: 5.494060 recon loss: 4.173867\n",
      "2100 loss: 5.497131 recon loss: 4.167235\n",
      "2200 loss: 5.497489 recon loss: 4.169603\n",
      "2300 loss: 5.498637 recon loss: 4.163640\n",
      "2400 loss: 5.496807 recon loss: 4.166883\n",
      "2500 loss: 5.498518 recon loss: 4.161799\n",
      "2600 loss: 5.500128 recon loss: 4.171433\n",
      "2700 loss: 5.484235 recon loss: 4.150394\n",
      "2800 loss: 5.486589 recon loss: 4.145640\n",
      "2900 loss: 5.498783 recon loss: 4.160924\n",
      "3000 loss: 5.491119 recon loss: 4.146468\n",
      "3100 loss: 5.493115 recon loss: 4.147088\n",
      "3200 loss: 5.499337 recon loss: 4.169775\n",
      "3300 loss: 5.477855 recon loss: 4.136701\n",
      "3400 loss: 5.487717 recon loss: 4.131732\n",
      "3500 loss: 5.493511 recon loss: 4.149113\n",
      "3600 loss: 5.481060 recon loss: 4.138755\n",
      "3700 loss: 5.483079 recon loss: 4.128724\n",
      "3800 loss: 5.489243 recon loss: 4.131364\n",
      "3900 loss: 5.487994 recon loss: 4.148529\n",
      "4000 loss: 5.487898 recon loss: 4.133420\n",
      "4100 loss: 5.492106 recon loss: 4.144313\n",
      "4200 loss: 5.475044 recon loss: 4.119466\n",
      "4300 loss: 5.484891 recon loss: 4.125149\n",
      "4400 loss: 5.491833 recon loss: 4.140519\n",
      "4500 loss: 5.480633 recon loss: 4.114383\n",
      "4600 loss: 5.485213 recon loss: 4.125689\n",
      "4700 loss: 5.479072 recon loss: 4.122387\n",
      "4800 loss: 5.488331 recon loss: 4.119585\n",
      "4900 loss: 5.481561 recon loss: 4.129916\n",
      "5000 loss: 5.481975 recon loss: 4.119986\n",
      "5100 loss: 5.487250 recon loss: 4.124388\n",
      "5200 loss: 5.475413 recon loss: 4.111020\n",
      "5300 loss: 5.493513 recon loss: 4.123342\n",
      "5400 loss: 5.475444 recon loss: 4.106256\n",
      "5500 loss: 5.478610 recon loss: 4.118227\n",
      "5600 loss: 5.482045 recon loss: 4.107317\n",
      "5700 loss: 5.477800 recon loss: 4.109369\n",
      "5800 loss: 5.486689 recon loss: 4.115146\n",
      "5900 loss: 5.473989 recon loss: 4.108557\n",
      "6000 loss: 5.485801 recon loss: 4.119777\n",
      "6100 loss: 5.480759 recon loss: 4.102416\n",
      "6200 loss: 5.481579 recon loss: 4.115242\n",
      "6300 loss: 5.485627 recon loss: 4.112252\n",
      "6400 loss: 5.468299 recon loss: 4.096112\n",
      "6500 loss: 5.483803 recon loss: 4.113656\n",
      "6600 loss: 5.471544 recon loss: 4.092218\n",
      "6700 loss: 5.482145 recon loss: 4.111858\n",
      "6800 loss: 5.484480 recon loss: 4.104024\n",
      "6900 loss: 5.470827 recon loss: 4.099753\n",
      "7000 loss: 5.487403 recon loss: 4.109121\n",
      "7100 loss: 5.477076 recon loss: 4.107619\n",
      "7200 loss: 5.480085 recon loss: 4.096792\n",
      "7300 loss: 5.477472 recon loss: 4.101046\n",
      "7400 loss: 5.470587 recon loss: 4.093493\n",
      "7500 loss: 5.478507 recon loss: 4.098876\n",
      "7600 loss: 5.479536 recon loss: 4.088171\n",
      "7700 loss: 5.483302 recon loss: 4.105808\n",
      "7800 loss: 5.474201 recon loss: 4.095092\n",
      "7900 loss: 5.484667 recon loss: 4.095577\n",
      "8000 loss: 5.474450 recon loss: 4.087096\n",
      "8100 loss: 5.468168 recon loss: 4.079902\n",
      "8200 loss: 5.475532 recon loss: 4.091459\n",
      "8300 loss: 5.478538 recon loss: 4.086087\n",
      "8400 loss: 5.471024 recon loss: 4.095979\n",
      "8500 loss: 5.480588 recon loss: 4.093634\n",
      "8600 loss: 5.468433 recon loss: 4.073638\n",
      "8700 loss: 5.486926 recon loss: 4.101657\n",
      "8800 loss: 5.469286 recon loss: 4.078864\n",
      "8900 loss: 5.475645 recon loss: 4.080210\n",
      "9000 loss: 5.464231 recon loss: 4.077709\n",
      "9100 loss: 5.478535 recon loss: 4.087459\n",
      "9200 loss: 5.469178 recon loss: 4.074161\n",
      "9300 loss: 5.472579 recon loss: 4.082830\n",
      "9400 loss: 5.471747 recon loss: 4.079492\n",
      "9500 loss: 5.479178 recon loss: 4.083578\n",
      "9600 loss: 5.472256 recon loss: 4.076171\n",
      "9700 loss: 5.468440 recon loss: 4.083306\n",
      "9800 loss: 5.474090 recon loss: 4.080776\n",
      "9900 loss: 5.475427 recon loss: 4.079102\n",
      "10000 loss: 5.476913 recon loss: 4.075409\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_training_updates = 10000\n",
    "\n",
    "train_losses = []\n",
    "recon_losses = []\n",
    "for step_index, data in enumerate(train_dataset):\n",
    "    train_results = train_step(data)\n",
    "    train_losses.append(train_results['loss'])\n",
    "    recon_losses.append(train_results['x_recon_loss'])\n",
    "    \n",
    "    if (step_index + 1) % 100 == 0:\n",
    "        print('%d loss: %f recon loss: %f' % (step_index+1, np.mean(train_losses[-100:]), np.mean(recon_losses[-100:])))\n",
    "        \n",
    "    if (step_index + 1) % num_training_updates == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_recon': <tf.Tensor: shape=(1999, 10, 2), dtype=float32, numpy=\n",
      "array([[[0.715759  , 0.28424105],\n",
      "        [0.8606288 , 0.13937123],\n",
      "        [0.9390734 , 0.0609266 ],\n",
      "        ...,\n",
      "        [0.96785396, 0.03214609],\n",
      "        [0.9381952 , 0.06180481],\n",
      "        [0.83525103, 0.16474903]],\n",
      "\n",
      "       [[0.21704927, 0.78295076],\n",
      "        [0.08958674, 0.91041327],\n",
      "        [0.03436255, 0.9656374 ],\n",
      "        ...,\n",
      "        [0.00699824, 0.99300176],\n",
      "        [0.01736357, 0.98263645],\n",
      "        [0.08281987, 0.9171801 ]],\n",
      "\n",
      "       [[0.85000676, 0.14999323],\n",
      "        [0.93578887, 0.06421115],\n",
      "        [0.96387565, 0.03612437],\n",
      "        ...,\n",
      "        [0.3102007 , 0.6897993 ],\n",
      "        [0.28209776, 0.71790224],\n",
      "        [0.34256205, 0.657438  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.36071262, 0.63928735],\n",
      "        [0.26478264, 0.73521733],\n",
      "        [0.17304373, 0.8269563 ],\n",
      "        ...,\n",
      "        [0.2753079 , 0.7246921 ],\n",
      "        [0.34822333, 0.6517767 ],\n",
      "        [0.3925557 , 0.60744435]],\n",
      "\n",
      "       [[0.556508  , 0.44349197],\n",
      "        [0.5960809 , 0.40391907],\n",
      "        [0.6362099 , 0.36379015],\n",
      "        ...,\n",
      "        [0.5583038 , 0.4416962 ],\n",
      "        [0.5280399 , 0.47196016],\n",
      "        [0.485765  , 0.51423496]],\n",
      "\n",
      "       [[0.03648835, 0.96351165],\n",
      "        [0.00326131, 0.99673873],\n",
      "        [0.00115912, 0.99884087],\n",
      "        ...,\n",
      "        [0.37662724, 0.6233728 ],\n",
      "        [0.72981375, 0.27018625],\n",
      "        [0.7308925 , 0.26910752]]], dtype=float32)>, 'x_recon_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.105092>, 'loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.543702>}\n"
     ]
    }
   ],
   "source": [
    "# Look at validation set\n",
    "model_output = catvae(is_test.astype(int))\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_array(a):\n",
    "    aa = []\n",
    "    for c in a:\n",
    "        if c == '0':\n",
    "            aa.append(0)\n",
    "        else:\n",
    "            aa.append(1)\n",
    "        \n",
    "    return np.array(aa)\n",
    "\n",
    "def bin_to_dec(b):\n",
    "    dec = 0\n",
    "    for idx, val in enumerate(b):\n",
    "        dec += val << (len(b) - idx - 1)\n",
    "        \n",
    "    return dec\n",
    "\n",
    "def update_counts(psi, vae, batch_size):\n",
    "    latent_dim = vae.encoder.latent_dim\n",
    "    z = tf.random.normal([batch_size, latent_dim], mean=0.0, stddev=1.0, dtype=tf.dtypes.float32)\n",
    "    output = vae.decoder(z)\n",
    "    vdim = output['x_recon'].shape[1]\n",
    "    \n",
    "    probs = tf.reshape(output['x_recon'], [-1, output['x_recon'].shape[-1]])\n",
    "    samples = tf.reshape(tf.random.categorical(tf.math.log(probs), 1), [batch_size, vdim]).numpy()\n",
    "    \n",
    "    for ii in range(samples.shape[0]):\n",
    "        idx = bin_to_dec(samples[ii,:])\n",
    "        psi[idx] += 1\n",
    "\n",
    "def get_psi(vae, num_samples):\n",
    "    n = vae.decoder.vdim\n",
    "    psi = np.zeros(2**n)\n",
    "    batch_size = 1000\n",
    "    total_samples = 0\n",
    "    while total_samples < num_samples:\n",
    "        update_counts(psi, vae, batch_size)\n",
    "        total_samples = total_samples + batch_size\n",
    "        \n",
    "    # Normalize\n",
    "    psi = np.sqrt(psi*(1.0/float(total_samples)))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "import math\n",
    "def get_psi_loss(vae, num_samples):\n",
    "    n = vae.decoder.vdim\n",
    "    norm = 0\n",
    "    psi = []\n",
    "    for d in range(2**n):\n",
    "        dbin = bit_array(np.binary_repr(d, width=n))\n",
    "        dbin_input = np.tile(dbin, (num_samples,1))\n",
    "        model_output = vae(dbin_input.astype(float))\n",
    "        val = np.exp(-0.5*model_output['loss'])\n",
    "        psi.append(val)\n",
    "        norm = norm + val*val\n",
    "    norm = math.sqrt(norm)\n",
    "    \n",
    "    for ii in range(len(psi)):\n",
    "        psi[ii] = psi[ii]/norm\n",
    "        \n",
    "    return np.array(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = get_psi(catvae, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(psi, psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28364943, 0.14852609, 0.10748023, ..., 0.10787956, 0.14757032,\n",
       "       0.28491402])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the wave function\n",
    "np.savetxt('/Users/tuckerkj/Google Drive/Research/QML/data/quc_examples/Tutorial1_TrainPosRealWaveFunction/ld_results/cat_vae_psi_2d.txt', psi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = vae.CatEncoder(intermediate_dim, latent_dim, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = encoder(tf.cast(is_test, tf.dtypes.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1999, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output['z'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = vae.CatDecoder(intermediate_dim, original_dim, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = decoder(encoder_output['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_recon': <tf.Tensor: shape=(1999, 10, 2), dtype=float32, numpy=\n",
       " array([[[0.3283945 , 0.6716055 ],\n",
       "         [0.24753737, 0.7524627 ],\n",
       "         [0.48549405, 0.51450604],\n",
       "         ...,\n",
       "         [0.84731066, 0.15268925],\n",
       "         [0.59798235, 0.40201768],\n",
       "         [0.48342746, 0.5165726 ]],\n",
       " \n",
       "        [[0.37522176, 0.6247783 ],\n",
       "         [0.5033799 , 0.49662015],\n",
       "         [0.52120245, 0.4787976 ],\n",
       "         ...,\n",
       "         [0.42249188, 0.5775081 ],\n",
       "         [0.35086215, 0.6491378 ],\n",
       "         [0.71415263, 0.28584743]],\n",
       " \n",
       "        [[0.28186828, 0.7181317 ],\n",
       "         [0.22574237, 0.77425766],\n",
       "         [0.50255436, 0.49744564],\n",
       "         ...,\n",
       "         [0.8840027 , 0.11599734],\n",
       "         [0.63462514, 0.3653749 ],\n",
       "         [0.48483124, 0.5151687 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.24717675, 0.7528232 ],\n",
       "         [0.45836413, 0.5416359 ],\n",
       "         [0.79527956, 0.20472042],\n",
       "         ...,\n",
       "         [0.3245397 , 0.67546034],\n",
       "         [0.07193395, 0.928066  ],\n",
       "         [0.9683022 , 0.03169781]],\n",
       " \n",
       "        [[0.25285468, 0.74714535],\n",
       "         [0.50952536, 0.4904747 ],\n",
       "         [0.53876233, 0.46123773],\n",
       "         ...,\n",
       "         [0.3400978 , 0.6599022 ],\n",
       "         [0.21724167, 0.7827583 ],\n",
       "         [0.872062  , 0.127938  ]],\n",
       " \n",
       "        [[0.29818556, 0.7018145 ],\n",
       "         [0.44031072, 0.55968934],\n",
       "         [0.53723013, 0.4627699 ],\n",
       "         ...,\n",
       "         [0.73668116, 0.26331884],\n",
       "         [0.5975779 , 0.402422  ],\n",
       "         [0.536826  , 0.46317393]]], dtype=float32)>}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "catvae = vae.CatVAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = catvae(is_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_recon': <tf.Tensor: shape=(1999, 10, 2), dtype=float32, numpy=\n",
       " array([[[0.15239543, 0.8476045 ],\n",
       "         [0.5892857 , 0.4107143 ],\n",
       "         [0.3920526 , 0.6079474 ],\n",
       "         ...,\n",
       "         [0.31885427, 0.6811457 ],\n",
       "         [0.21401262, 0.78598744],\n",
       "         [0.893004  , 0.10699599]],\n",
       " \n",
       "        [[0.27435914, 0.7256409 ],\n",
       "         [0.2201425 , 0.7798576 ],\n",
       "         [0.50451887, 0.4954811 ],\n",
       "         ...,\n",
       "         [0.89069873, 0.10930119],\n",
       "         [0.6404785 , 0.3595215 ],\n",
       "         [0.48500305, 0.51499695]],\n",
       " \n",
       "        [[0.349085  , 0.650915  ],\n",
       "         [0.4758491 , 0.52415085],\n",
       "         [0.70569   , 0.2943099 ],\n",
       "         ...,\n",
       "         [0.398407  , 0.601593  ],\n",
       "         [0.17368652, 0.8263135 ],\n",
       "         [0.88728225, 0.11271767]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.05984537, 0.9401547 ],\n",
       "         [0.30925807, 0.69074196],\n",
       "         [0.623171  , 0.37682903],\n",
       "         ...,\n",
       "         [0.96722454, 0.0327754 ],\n",
       "         [0.7883375 , 0.2116625 ],\n",
       "         [0.6104322 , 0.38956785]],\n",
       " \n",
       "        [[0.36132422, 0.6386758 ],\n",
       "         [0.4429648 , 0.5570352 ],\n",
       "         [0.5344195 , 0.4655805 ],\n",
       "         ...,\n",
       "         [0.689266  , 0.31073397],\n",
       "         [0.58016235, 0.41983762],\n",
       "         [0.5119712 , 0.48802882]],\n",
       " \n",
       "        [[0.6456861 , 0.3543139 ],\n",
       "         [0.6525407 , 0.34745935],\n",
       "         [0.89437646, 0.10562351],\n",
       "         ...,\n",
       "         [0.6229069 , 0.37709302],\n",
       "         [0.23100828, 0.76899177],\n",
       "         [0.77189034, 0.22810964]]], dtype=float32)>,\n",
       " 'x_recon_loss': <tf.Tensor: shape=(), dtype=float32, numpy=8.092544>,\n",
       " 'loss': <tf.Tensor: shape=(), dtype=float32, numpy=8.2788105>}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdim = decoder_output['x_recon'].shape[1]\n",
    "    \n",
    "probs = tf.reshape(decoder_output['x_recon'], [-1, decoder_output['x_recon'].shape[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(19990, 2), dtype=float32, numpy=\n",
       "array([[0.3283945 , 0.6716055 ],\n",
       "       [0.24753737, 0.7524627 ],\n",
       "       [0.48549405, 0.51450604],\n",
       "       ...,\n",
       "       [0.73668116, 0.26331884],\n",
       "       [0.5975779 , 0.402422  ],\n",
       "       [0.536826  , 0.46317393]], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tf.random.categorical(tf.math.log(probs), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1999, 10), dtype=int64, numpy=\n",
       "array([[1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 1, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 1, 1, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(samples, [1999, vdim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
